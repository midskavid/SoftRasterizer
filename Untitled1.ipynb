{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import autograd\n",
    "import pdb\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuruMeditation (autograd.detect_anomaly):  \n",
    "    def __init__(self):\n",
    "        super(GuruMeditation, self).__init__()  \n",
    "    def __enter__(self):\n",
    "        super(GuruMeditation, self).__enter__()\n",
    "        return self  \n",
    "    def __exit__(self, type, value, trace):\n",
    "        super(GuruMeditation, self).__exit__()\n",
    "        if isinstance(value, RuntimeError):\n",
    "            traceback.print_tb(trace)\n",
    "            halt(str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def halt(msg):\n",
    "    print (msg)\n",
    "    pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFunc(autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inp):\n",
    "        return inp.clone()\n",
    "    @staticmethod\n",
    "    def backward(ctx, gO):\n",
    "        # Error during the backward pass\n",
    "        raise RuntimeError(\"Some error in backward\")\n",
    "        return gO.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fn(a):\n",
    "    out = MyFunc.apply(a)\n",
    "    return out.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: RuntimeWarning: Traceback of forward call that caused the error:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-18-79a76f9bb1ff>\", line 3, in <module>\n",
      "    out = run_fn(inp)\n",
      "  File \"<ipython-input-15-72f757742a51>\", line 2, in run_fn\n",
      "    out = MyFunc.apply(a)\n",
      "\n",
      "  File \"<ipython-input-18-79a76f9bb1ff>\", line 4, in <module>\n",
      "    out.backward()\n",
      "  File \"/home/mridul/.local/lib/python3.5/site-packages/torch/tensor.py\", line 107, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/home/mridul/.local/lib/python3.5/site-packages/torch/autograd/__init__.py\", line 93, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "  File \"/home/mridul/.local/lib/python3.5/site-packages/torch/autograd/function.py\", line 77, in apply\n",
      "    return self._forward_cls.backward(self, *args)\n",
      "  File \"<ipython-input-14-909817fdcbb3>\", line 8, in backward\n",
      "    raise RuntimeError(\"Some error in backward\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some error in backward\n",
      "--Return--\n",
      "> <ipython-input-17-9a2ccd310de5>(3)halt()->None\n",
      "-> pdb.set_trace()\n",
      "(Pdb) inp\n",
      "tensor([[0.8113, 0.4391, 0.8450, 0.0284, 0.6086, 0.4657, 0.1226, 0.6760, 0.9095,\n",
      "         0.3319],\n",
      "        [0.1264, 0.4520, 0.6680, 0.5794, 0.7973, 0.6531, 0.5496, 0.6965, 0.3998,\n",
      "         0.6782],\n",
      "        [0.8351, 0.2687, 0.5938, 0.1803, 0.7886, 0.2239, 0.3521, 0.5001, 0.9874,\n",
      "         0.1824],\n",
      "        [0.1552, 0.6452, 0.0468, 0.3970, 0.0830, 0.0336, 0.5148, 0.0583, 0.0158,\n",
      "         0.5246],\n",
      "        [0.6229, 0.5873, 0.4143, 0.5263, 0.7453, 0.9539, 0.1887, 0.4381, 0.5695,\n",
      "         0.6445],\n",
      "        [0.4297, 0.2430, 0.5396, 0.5723, 0.5262, 0.5215, 0.9813, 0.6572, 0.1489,\n",
      "         0.6500],\n",
      "        [0.0665, 0.3368, 0.1870, 0.5527, 0.7454, 0.6998, 0.9293, 0.3963, 0.3054,\n",
      "         0.0675],\n",
      "        [0.3791, 0.0631, 0.8119, 0.3459, 0.4347, 0.8189, 0.3260, 0.4167, 0.4448,\n",
      "         0.7146],\n",
      "        [0.8482, 0.6092, 0.0388, 0.3070, 0.3934, 0.4365, 0.6081, 0.8230, 0.3022,\n",
      "         0.5185],\n",
      "        [0.9504, 0.2764, 0.6774, 0.0990, 0.5335, 0.9533, 0.9643, 0.9911, 0.6568,\n",
      "         0.7572]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with GuruMeditation() as gr :\n",
    "    inp = torch.rand(10, 10, requires_grad=True)\n",
    "    out = run_fn(inp)\n",
    "    out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
